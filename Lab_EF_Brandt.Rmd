---
title: "Lab E/F - SOCI709"
author: "Kate Brandt"
date: "February 10, 2019"
output: pdf_document
---

```{r, echo=FALSE}
library(tinytex)
```


## Q1. What size N seems to make the bimodal distribution look normal?
   
   * The greater the N, the more normal the distribution appears. The three images below show how the distribution becomes normal as N increases from 1 to 3 to 6. An N of 1 most prominently shows the bimodal distribution becacuse each sample's average equals the one sample. As the N increases, the distribution of each sample is the average of the N samples, so the distribution is distributed around the mean of the two modes. By about N = 5 or N = 6, the bimodal distribution appears normal.

  **N = 1**
```{r, out.width="250px", echo = FALSE}
knitr::include_graphics("biomodal_1.JPG")

```

  
  
  **N = 3**
```{r, out.width="250px", echo = FALSE}
knitr::include_graphics("bimodal_3.JPG")

```
 
  
  
  
  
  **N = 6**
```{r, out.width="250px", echo = FALSE}
knitr::include_graphics("bimodal_6.jpg")


```
  
  
  
  

## Q2. Monte Carlo simulation of the variance b
  
  For this part of the assignment, I used the MonteCalo package in R.
  The link which explains the functionality of this package can be found **[here](https://cran.r-project.org/web/packages/MonteCarlo/vignettes/MonteCarlo-Vignette.html)**
  
  
```{r, warning=FALSE, error=FALSE, message=FALSE, results='hide'}
#Setting up
#Loading package
library(MonteCarlo)
library(dplyr)
library(tinytex)

#The following recreates the estols2.ado file
estols2 <- function(n, xmean=0, x_sd=3, emean=0, e_sd=15, xcoef=3){

# The following steps are based on Lab E STATA code
# Create data for x, y, and e

# Create sample x [from STATA: "gen x=3*invnorm(uniform())"]
#(standard deviation = 3, mean = 0)
x <- rnorm(n, mean = xmean, sd = x_sd)

#Create sample e [from STATA: "gen e=15*invnorm(uniform())"
e <- rnorm(n, mean = emean, sd = e_sd)

#Create sample y
y <- xcoef*x+e

#create data frame to regress
df <- data.frame(y,x,e)

#output regression
model <- (lm(y~x, data = df))
coeflist <- model$coefficients[2] %>% unname

return(list("coeflist" = coeflist))
}

# Use the estols2 function to run Monte Carlo simulations with different parameters
# MonteCarlo takes 3 arguments: function, reps, and grid of parameters for function
# Define parameter grid
n_grid <- 300
param <- list("n"=n_grid)
estols2(n_grid)
MC_q2_a <- MonteCarlo(func = estols2, nrep = 200, param_list = param)

```
```{r, warning=FALSE, error=FALSE, message=FALSE}
#Summarize output with table and graph
library(ggplot2)
MC_2a <- MakeFrame(MC_q2_a)
tbl_2a <- tbl_df(MC_2a)
coef2a <- tbl_2a$coeflist
summary(coef2a)
sd(coef2a)
```
```{r, warning=FALSE, error=FALSE, message=FALSE, echo=FALSE}

tbl_2a %>% ggplot()+geom_density(aes(x= coeflist)) + labs(title="(Q2a) Observed Distribution of B", subtitle = "N=300, reps=200, normal error distribution (based on estols2 parameters)", xlab="simulated coefficients", ylab="density")
```

 Q2, Part B: N=30, reps=300
```{r, warning=FALSE, error=FALSE, message=FALSE, results='hide'}
n_grid <- 30
param <- list("n"=n_grid)
estols2(n_grid)
MC_q2_b <- MonteCarlo(func = estols2, nrep = 300, param_list = param)

```
```{r, warning=FALSE, error=FALSE, message=FALSE}
#Summarize output with table and graph
library(ggplot2)
MC_2b <- MakeFrame(MC_q2_b)
tbl_2b <- tbl_df(MC_2b)
coef2b <- tbl_2b$coeflist
summary(coef2b)
sd(coef2b)
```
```{r, warning=FALSE, error=FALSE, message=FALSE, echo=FALSE}
tbl_2b %>% ggplot()+geom_density(aes(x= coeflist)) + labs(title="(Q2b) Observed Distribution of B", subtitle = "N=30, reps=300, normal error distribution (based on estols2 parameters)", xlab="simulated coefficients", ylab="density")
```

## Q3.Simulating different error terms
  
  The following is based on recreating the test_dist.do
```{r, warning=FALSE, error=FALSE, message=FALSE, results='hide'}
# Using rbeta() command to simulate beta distribution. Previous problems were using rnorm() for normal distributions

# obs = 2000

q3_a <- rbeta(2000, 0.2, 0.2)
```
```{r, warning=FALSE, error=FALSE, message=FALSE, echo=FALSE}
q3a <- data.frame(q3_a)
q3a %>% ggplot()+geom_density(aes(x=q3_a)) + labs(title="(Q3a) Observed Distribution of B", subtitle = "reps=2000, bimodal distribution (alpha = 0.2, beta = 0.2)", xlab="simulated beta", ylab="density")
```

  Substitute this command for estols2.ado (from question 2)
  This will end up being written in the syntax as:
    e_q3 <- 15*rbeta(n, shape1 = 0.2, shape2 = 0.2)
```{r, warning=FALSE, error=FALSE, message=FALSE, results='hide', echo=FALSE}
#Setting up
#Loading package
library(MonteCarlo)
library(dplyr)
library(tinytex)

#The following recreates the estols2.ado file
estols2 <- function(n, xmean=0, x_sd=3, emean=0, e_sd=15, xcoef=3){

# The following steps are based on Lab E STATA code
# Create data for x, y, and e

# Create sample x [from STATA: "gen x=3*invnorm(uniform())"]
#(standard deviation = 3, mean = 0)
x <- rnorm(n, mean = xmean, sd = x_sd)

#Create sample e [from STATA: "gen e=15*invnorm(uniform())"
e <- 15*rbeta(n, shape1 = 0.2, shape2 = 0.2)

#Create sample y
y <- xcoef*x+e

#create data frame to regress
df <- data.frame(y,x,e)

#output regression
model <- (lm(y~x, data = df))
coeflist <- model$coefficients[2] %>% unname

return(list("coeflist" = coeflist))
}

# Use the estols2 function to run Monte Carlo simulations with different parameters
# MonteCarlo takes 3 arguments: function, reps, and grid of parameters for function
# Define parameter grid
n_grid <- 200
param <- list("n"=n_grid)
estols2(n_grid)
MC_q3b <- MonteCarlo(func = estols2, nrep = 200, param_list = param)

```
```{r, warning=FALSE, error=FALSE, message=FALSE, echo=FALSE}
#Summarize output with table and graph
library(ggplot2)
MC_3b <- MakeFrame(MC_q3b)
tbl_3b <- tbl_df(MC_3b)
```
```{r, warning=FALSE, error=FALSE, message=FALSE, echo=FALSE}

tbl_3b %>% ggplot()+geom_density(aes(x= coeflist)) + labs(title="(Q3b) Observed Distribution of B", subtitle = "N=200, reps=200, beta distribution of error term (alpha = 0.2, beta = 0.2)", xlab="simulated coefficients", ylab="density")
```

  
  This beta error term distribution, using the simulated data samples, seems to result in a slightly abnormal distribution of b, but not one that is much more noticeable than the abnormalities from the normal distributions in Q2. This is perhaps because of the nigh number of N and high number of reps. Even abnormal distributions, repeated enough times and added together, can appear normal. In experimenting with the distribution module from question 1, it seems as though an N as small as 5 can begin result in a seemingly even distribution as the observations from each experiment average out. In part A of this question, the beta distribution experiment was conducted 2000 times, but with one observation per rep. This is what allowed the distribution to appear bimodal. This is also why, with 200 reps and N=200 in part B, the distribution appears mostly normal.
  
  
##Q4. How do these simulations constitute an "experiment" of the validity of asymptotic normality of the distribution of b?

  All of these simulations create sets of randomly generated values from a speficied distribution. From these sets, each "experiment" is conducted by a random selection from the data set to be analyzed (in this case, regressed). Each regression produces a coefficient, b, which describes the relationship between y and x. Calculations of these coefficients, repeatedly, generate a set of estimated "B" values which can be plotted to determine density of the estimations. This is an experiment because of the randomness of the data and selected samples, and the repititions which accumulate a mass of data points. Though these are simulated data, the randomness of the set error term (via normal or beta density) allow for variation. this is why we plot the estimated values: to assess the effect of the error term.